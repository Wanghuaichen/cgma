#!/usr/bin/ksh

# Basic Syntax:
#  Anything of the form X=Value is
#    a variable assignement
#  Anything starting with a - is a
#    command-line option
#  Anything else is a test key.
#  Examples: cgm_test MAP
#            cgm_test -config my.config COMMIT

# How to use this script
# ----------------------
# This script runs the CUBIT tests in a variety of scenarios.
# Four steps are carried out:
#
#  1) CVS update in 0, 1, or more directories
#  2) Build commands, such as make
#  3) Tests are run
#  4) Post-test commands are run if the tests are all successful
#
# All steps except 3) can be skipped, and are skipped if you use
# the default variable values.
#
# You indicate your specific needs by setting variable values.
# Variable values can be set in a variety of ways, listed here
# in order of increasing precedence:
#
# 1) default values (acts like my_cubit_test)
# 2) environment variables
# 3) config file (cgm_test.config by default)
# 4) command line options
#
# The config file
# ---------------
# Variable values are read from a config file.  The default name
# for this config file is cgm_test.config, in the current directory.
# You can use another file as a config file using the command line
# option "-config filename" (without the quotes), or by setting the
# environment variable CGM_TEST_CONFIG.
#
# The config file holds variable values, set just like you would in
# a makefile.  Here is an example line:
#  
# MAIL_SUBJECT = "Here are the test results"
#
# Variables descriptions
# ----------------------
# These are the variables you can set to control this script,
# along with their default values:
# 
#  TEST_EXEC (cubit)
#   the executable used in testing
#
#  TEST_EXEC_OPT ("-nographics -nojournal -noinit -batch")
#   the command line options used to execute cubit during testing
#
#  TEST_DIR ("/usr/local/eng_sci/cubit/beta/cubit_test")
#   The directory the tests are located in.
#
#  CVS_DIRS ("")
#   Directories in which cvs update should be run. Multiple directories
#   should be separated by a space.  To update the current directory and
#   the test directory, for example, you would use this line:
#     CVS_DIRS = $TEST_DIR `pwd`
#
#  MAKE ("make")
#   The command used to run the tests.  You can change this to enable
#   parallel make.
#
#  BUILD_COMMANDS ("")
#   Commands run after cvs and before tests are run.  Here is an example you
#   may want to use:
#   BUILD_COMMANDS = ${MAKE} clean; ${MAKE}
#
#  MAIL_COMPLETE ("")
#   E-mail addresses that will be mailed a full copy of the results file.
#   Multiple addresses should be separated by a space.
#
#  MAIL_SUMMARY ("")
#   E-mail addresses that will be mailed a summary of test results.
#   Multiple addresses should be separated by a space.
#
#  MAIL_FAILURE ("")
#   E-mail addresses that will be mailed a summary of test results, but
#   only if tests fail. Multiple addresses should be separated by a space.
#
#  MAIL_SUBJECT ("CUBIT Test Results: `date '+%a %b %e %I:%M %p'`")
#   Subject line of e-mail sent by this script.
#
#  MAIL_COMMAND ("| Mail -s '\${MAIL_SUBJECT}'")
#   Command used to send mail from your system.
#
#  RESULTS_FILE ("result")
#   Name of the results file generated by this script.
#
#  RESULTS_FILE2 ("result.new")
#   Name of the second copy of the results file generated by this script.
#
#  REPEAT_COMMAND ("")
#   The command used to run this script again.  Here is an example
#   that will run the test every 24 hours with the same command line:
#    REPEAT_COMMAND = eval echo $0 "$@" | at -c 01:00 tomorrow
#
#  TEST_KEYS=${TEST_KEYS-""}
#    The test keys to be run.  Usually set in the command line.
#
#  CGM_TEST_CONFIG (cgm_test.config)
#   The name of the file holding configuration info.
#
#  TEMP ("/usr/tmp")
#   Where temporary files should be stored.  Uses environment
#   variables TEMP, TMP, or TEMPDIR, if set.
#
#  POST_TEST_COMMANDS ("")
#   Commands that are executed if all tests are successful.
#
#  USE_MAKE_TO_TEST (0)
#   Whether to use $MAKE to carry out the tests.  If make is not used,
#   testing is done in this script, one at a time.  Using make on
#   some systems allows the tests to be run in parallel.  On other
#   systems, shell limitations cause problems if you use make for testing.
#   Set this to 1 to use make, 0 to not use make.
#
#  OUTPUT_TIME ("")
#   Whether to output timing specific information for each test

#Define functions
function write_section_begin {
  echo >> $2
  echo "*************************\n*" >> $2
  echo "* $1" >> $2
  print -n "* " >> $2
  integer str_size
  str_size=${#1}
  while [ $str_size -gt 0 ]; do
    print -n - - >> $2
    str_size=`expr $str_size - 1`
  done
  echo "\n*" >> $2
}

function write_section_end {
  echo "*\n*************************\n" >> $1
}
  
function write_results_file {
  echo "\nReport on CGM testing done in $pwd_dir" > $RESULTS_FILE
  echo "  on `date +'%a %b %e, %Y at %T'`" >> $RESULTS_FILE
  write_section_begin SUMMARY $RESULTS_FILE
  
  # Print out summary of CVS
  if [ $cvs_errors != 0 ]; then
    print -n "* ERROR - 'cvs update' produced errors or conflicts in " >> $RESULTS_FILE
    echo "$cvs_errors of $num_cvs_dirs directories" >> $RESULTS_FILE
    for dir in $CVS_DIRS
    do
      echo "*  " $dir >> $RESULTS_FILE
    done
  elif [ $num_cvs_dirs -ne 0 ]; then
    echo "* 'cvs update' successful in all $num_cvs_dirs directories" >> $RESULTS_FILE
    for dir in $CVS_DIRS
    do
      echo "*   " $dir >> $RESULTS_FILE
    done
    echo "* " >> $RESULTS_FILE
  fi
  
  # Print out summary of build commands
  if [ -n "$BUILD_COMMANDS" ]; then
    if [ $cvs_errors -ne 0 ]; then
      echo "* Build commands not run due to previous errors" >> $RESULTS_FILE
    elif [ $build_errors -eq 0 ]; then
      echo "* Build commands successful" >> $RESULTS_FILE
      echo "*   commands: " ${BUILD_COMMANDS} "\n*" >> $RESULTS_FILE
    else
      echo "* ERROR - Build commands NOT successful" >> $RESULTS_FILE
      echo "*     " "$BUILD_COMMANDS" >> $RESULTS_FILE
      # cvs_errors is used as a generic error flag from this point on
      cvs_errors=1
    fi
  fi
  
  # Print out summary of Tests
  if [ $cvs_errors -ne 0 ]; then
    echo "Tests not run due to previous errors"
  elif [ ! -n "$tests_with_errors" ]; then
    echo "* No tests had unexpected errors" >> $RESULTS_FILE
    echo "*    Test Keys:" $TEST_KEYS >> $RESULTS_FILE
    echo "*" >> $RESULTS_FILE
  else
    echo "* ERROR - `echo $tests_with_errors | wc -w | awk '{print $1}'`" \
         "tests had errors" >> $RESULTS_FILE
    echo "*    Test Keys:" $TEST_KEYS >> $RESULTS_FILE
    echo "*    Tests with errors:" $tests_with_errors >> $RESULTS_FILE
    cvs_errors=1
  fi
  
  # Print out summary of post-test commands
  if [ -n "$POST_TEST_COMMANDS" ]; then
    if [ $cvs_errors -ne 0 ]; then
      echo "Post-test commands not run due to previous errors" >> $RESULTS_FILE
    elif [ $post_test_errors -eq 0 ]; then
      echo "* Post-test commands successful" >> $RESULTS_FILE
      echo "*   Post-test commands:" $POST_TEST_COMMANDS >> $RESULTS_FILE
    else
      echo "* ERROR - Post-test commands NOT successful" >> $RESULTS_FILE
      echo "* Post-test commands:" $POST_TEST_COMMANDS >> $RESULTS_FILE
      cvs_errors=1
    fi
  fi

  write_section_end $RESULTS_FILE

  # Mail out summaries to those that need one
  if [ -n "$MAIL_SUMMARY" ]; then
    eval cat $RESULTS_FILE $MAIL_COMMAND $MAIL_SUMMARY
  fi
  if [ -n "$MAIL_FAILURE" -a $cvs_errors -ne 0 ]; then
    eval cat $RESULTS_FILE $MAIL_COMMAND $MAIL_FAILURE
  fi
  
  # Now append everything else
  if [ $num_cvs_dirs -ne 0 -a -r $TEMP/cvs.$$ ]; then
    cat $TEMP/cvs.$$ >> $RESULTS_FILE
  fi
  if [ -n "$BUILD_COMMANDS" -a -r $TEMP/build.$$ ]; then
    cat $TEMP/build.$$ >> $RESULTS_FILE
  fi
  if [ -r $TEMP/test.$$ ]; then
    cat $TEMP/test.$$ >> $RESULTS_FILE
  fi
  # Post-test output is appended to test.$$, so we're done

  # Get rid of temporary files
  $RM -f $TEMP/*.$$

  # Mail out complete results to those that need them
  if [ -n "$MAIL_COMPLETE" ]; then
    eval cat $RESULTS_FILE $MAIL_COMMAND $MAIL_COMPLETE
  fi
}

function initialize_variables {
  # Initialize variables that aren't dependent on environment variables
  debug=0
  pwd_dir=`pwd`
  RM=/bin/rm
  cvs_errors=0
  num_cvs_dirs=0
  build_errors=0
  test_errors=0
  post_test_errors=0
  tests_with_errors=""

  # Initialize variables to default values,
  # or the value of environment variables if set.
  TEST_EXEC=${TEST_EXEC-"cubit"}
  USE_MAKE_TO_TEST=${USE_MAKE_TO_TEST-"0"}
  TEST_EXEC_OPT=${TEST_EXEC_OPT-"-nographics -nojournal -noinit -batch"}
  TEST_DIR=${TEST_DIR-"/usr/local/eng_sci/cubit/beta/cubit_test"}
  CVS_DIRS=${CVS_DIRS-""}
  MAKE=${MAKE-"make"}
  BUILD_COMMANDS=${BUILD_COMMANDS-""}
  MAIL_COMPLETE=${MAIL_COMPLETE-""}
  MAIL_SUMMARY=${MAIL_SUMMARY-""}
  MAIL_FAILURE=${MAIL_FAILURE-""}
  MAIL_SUBJECT=${MAIL_SUBJECT-"CUBIT Test Results: `date '+%a %b %e %I:%M %p'`"}
  MAIL_COMMAND=${MAIL_COMMAND-"| Mail -s '\${MAIL_SUBJECT}'"}
  RESULTS_FILE=${RESULTS_FILE-"result"}
  RESULTS_FILE2=${RESULTS_FILE2-"result.new"}
  REPEAT_COMMAND=${REPEAT_COMMAND-""}
  TEST_KEYS=${TEST_KEYS-""}
  cgm_test_config=${CGM_TEST_CONFIG-cgm_test.config}
  TEMP=${TEMP:-${TMPDIR:-${TMP:-"/usr/tmp"}}}
  POST_TEST_COMMANDS=${POST_TEST_COMMANDS-""}
  OUTPUT_TIME=${OUTPUT_TIME-""}

  # See if the user requested a different config file on the command line.
  # Also check for command line options that we want to set right off
  config_opt=0
  for opt do
    if [ $config_opt -eq 1 ]; then
      cgm_test_config=$opt
    elif [ $opt = "-config" ]; then
      config_opt=1
    elif [ $opt = "-debug" ]; then
      debug=1
    fi
  done
  
  # Process the config file.
  # Values stored there will over-write any
  # environment variable values.
  if [ -n "$cgm_test_config" ] && [ -f $cgm_test_config ]; then
    if [ $config_opt -eq 1 ]; then
      config_opt=0
      if [ -n "`grep '^ *CGM_TEST_CONFIG *=' $cgm_test_config`" ]; then
        CGM_TEST_CONFIG=`nawk "-F *= *" '/^ *CGM_TEST_CONFIG *=/{print $2; exit}' $cgm_test_config`
      fi
    fi
    if [ -n "`grep '^ *USE_MAKE_TO_TEST *=' $cgm_test_config`" ]; then
      USE_MAKE_TO_TEST=`nawk "-F *= *" '/^ *USE_MAKE_TO_TEST *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *TEST_EXEC *=' $cgm_test_config`" ]; then
      TEST_EXEC=`nawk "-F *= *" '/^ *TEST_EXEC *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *TEST_EXEC_OPT *=' $cgm_test_config`" ]; then
      TEST_EXEC_OPT=`nawk "-F *= *" '/^ *TEST_EXEC_OPT *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *TEST_DIR *=' $cgm_test_config`" ]; then
      TEST_DIR=`nawk "-F *= *" '/^ *TEST_DIR *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *CVS_DIRS *=' $cgm_test_config`" ]; then
      CVS_DIRS=`nawk "-F *= *" '/^ *CVS_DIRS *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *MAKE *=' $cgm_test_config`" ]; then
      MAKE=`nawk "-F *= *" '/^ *MAKE *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *BUILD_COMMANDS *=' $cgm_test_config`" ]; then
      BUILD_COMMANDS=`nawk "-F *= *" '/^ *BUILD_COMMANDS *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *MAIL_COMPLETE *=' $cgm_test_config`" ]; then
      MAIL_COMPLETE=`nawk "-F *= *" '/^ *MAIL_COMPLETE *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *MAIL_SUMMARY *=' $cgm_test_config`" ]; then
      MAIL_SUMMARY=`nawk "-F *= *" '/^ *MAIL_SUMMARY *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *MAIL_FAILURE *=' $cgm_test_config`" ]; then
      MAIL_FAILURE=`nawk "-F *= *" '/^ *MAIL_FAILURE *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *MAIL_SUBJECT *=' $cgm_test_config`" ]; then
      MAIL_SUBJECT=`nawk "-F *= *" '/^ *MAIL_SUBJECT *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *MAIL_COMMAND *=' $cgm_test_config`" ]; then
      MAIL_COMMAND=`nawk "-F *= *" '/^ *MAIL_COMMAND *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *RESULTS_FILE *=' $cgm_test_config`" ]; then
      RESULTS_FILE=`nawk "-F *= *" '/^ *RESULTS_FILE *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *RESULTS_FILE2 *=' $cgm_test_config`" ]; then
      RESULTS_FILE2=`nawk "-F *= *" '/^ *RESULTS_FILE2 *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *REPEAT_COMMAND *=' $cgm_test_config`" ]; then
      REPEAT_COMMAND=`nawk "-F *= *" '/^ *REPEAT_COMMAND *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *TEST_KEYS *=' $cgm_test_config`" ]; then
      TEST_KEYS=`nawk "-F *= *" '/^ *TEST_KEYS *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *TEMP *=' $cgm_test_config`" ]; then
      TEMP=`nawk "-F *= *" '/^ *TEMP *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *POST_TEST_COMMANDS *=' $cgm_test_config`" ]; then
      POST_TEST_COMMANDS=`nawk "-F *= *" '/^ *POST_TEST_COMMANDS *=/{print $2; exit}' $cgm_test_config`
    fi
    if [ -n "`grep '^ *OUTPUT_TIME *=' $cgm_test_config`" ]; then
      OUTPUT_TIME=`nawk "-F *= *" '/^ *OUTPUT_TIME *=/{print $2; exit}' $cgm_test_config`
    fi
  fi
  
  # Now process the command line.  Options
  # set there will over-write any values
  # set so far, whether in the init file or
  # as an environment variable
  config_opt=0
  for opt do
    # See if this is one we skip
    if [ $config_opt -eq 1 ]; then
      config_opt=0
    # See if it has an equals sign in it
    elif [ -n "`print -n - $opt | grep '='`" ]; then
      # Get the portion before the '='
      opt_name=`print -n - $opt | nawk "-F *= *" '{printf ("%s", $1)}`
      # Get the portion after the '='
      opt_val=`print -n - $opt | nawk "-F *= *" '{printf ("%s", $2)}`
      case $opt_name in
        (USE_MAKE_TO_TEST)
                USE_MAKE_TO_TEST=$opt_val;;
        (TEST_EXEC)
                TEST_EXEC=$opt_val;;
        (TEST_EXEC_OPT)
                TEST_EXEC_OPT=$opt_val;;
        (TEST_DIR)
                TEST_DIR=$opt_val;;
        (CVS_DIRS)
                CVS_DIRS=$opt_val;;
        (MAKE)
                MAKE=$opt_val;;
        (BUILD_COMMANDS)
                BUILD_COMMANDS=$opt_val;;
        (MAIL_COMPLETE)
                MAIL_COMPLETE=$opt_val;;
        (MAIL_SUMMARY)
                MAIL_SUMMARY=$opt_val;;
        (MAIL_FAILURE)
                MAIL_FAILURE=$opt_val;;
        (MAIL_SUBJECT)
                MAIL_SUBJECT=$opt_val;;
        (MAIL_COMMAND)
                MAIL_COMMAND=$opt_val;;
        (RESULTS_FILE)
                RESULTS_FILE=$opt_val;;
        (RESULTS_FILE2)
                RESULTS_FILE2=$opt_val;;
        (REPEAT_COMMAND)
                REPEAT_COMMAND=$opt_val;;
        (TEST_KEYS)
                TEST_KEYS=$opt_val;;
        (TEMP)
                TEMP=$opt_val;;
        (POST_TEST_COMMANDS)
                POST_TEST_COMMANDS=$opt_val;;
        (OUTPUT_TIME)
                OUTPUT_TIME=$opt_val;;
      esac
    elif [ $opt = "-config" ]; then
      config_opt=1
    else
      if [ -n "`print -n - $opt | grep "^-"`" ]; then
        # Any command line switches we don't explicitly handle in
        # an elif clause are either handled elsewhere or are ignored.
         :
      else
        TEST_KEYS=`print -n - $TEST_KEYS $opt`
      fi
    fi
  done
  
  # As a debug, printout the values used for this test
  if [ $debug -eq 1 ]; then
    echo
    echo USE_MAKE_TO_TEST = $USE_MAKE_TO_TEST
    echo TEST_EXEC = $TEST_EXEC
    echo TEST_EXEC_OPT = $TEST_EXEC_OPT
    echo TEST_DIR = $TEST_DIR
    echo CVS_DIRS = $CVS_DIRS
    echo MAKE = $MAKE
    echo BUILD_COMMANDS = $BUILD_COMMANDS
    echo MAIL_COMPLETE = $MAIL_COMPLETE
    echo MAIL_SUMMARY = $MAIL_SUMMARY
    echo MAIL_FAILURE = $MAIL_FAILURE
    echo MAIL_SUBJECT = $MAIL_SUBJECT
    echo MAIL_COMMAND = $MAIL_COMMAND
    echo RESULTS_FILE = $RESULTS_FILE
    echo RESULTS_FILE2 = $RESULTS_FILE2
    echo REPEAT_COMMAND = $REPEAT_COMMAND
    echo TEST_KEYS = $TEST_KEYS
    echo TEMP = $TEMP
    echo POST_TEST_COMMANDS = $POST_TEST_COMMANDS
    echo OUTPUT_TIME = $OUTPUT_TIME
  fi
}

function check_variables {
  # Expand variables that may be in terms
  # of one or more other variables
  TEMP=`eval echo "\"${TEMP}\""`
  USE_MAKE_TO_TEST=`eval echo "\"${USE_MAKE_TO_TEST}\""`
  TEST_EXEC=`eval echo "\"${TEST_EXEC}\""`
  TEST_DIR=`eval echo "\"${TEST_DIR}\""`
  CVS_DIRS=`eval echo "\"${CVS_DIRS}\""`
  MAKE=`eval echo "\"${MAKE}\""`
  BUILD_COMMANDS=`eval echo "\"${BUILD_COMMANDS}\""`
  MAIL_COMPLETE=`eval echo "\"${MAIL_COMPLETE}\""`
  MAIL_SUMMARY=`eval echo "\"${MAIL_SUMMARY}\""`
  MAIL_FAILURE=`eval echo "\"${MAIL_FAILURE}\""`
  MAIL_SUBJECT=`eval echo "\"${MAIL_SUBJECT}\""`
  MAIL_COMMAND=`eval echo "\"${MAIL_COMMAND}\""`
  RESULTS_FILE=`eval echo "\"${RESULTS_FILE}\""`
  RESULTS_FILE2=`eval echo "\"${RESULTS_FILE2}\""`
  REPEAT_COMMAND=`eval echo "\"${REPEAT_COMMAND}\""`
  POST_TEST_COMMANDS=`eval echo "\"${POST_TEST_COMMANDS}\""`
  OUTPUT_TIME=`eval echo "\"${OUTPUT_TIME}\""`
  
  # As a debug, printout the values used for this test
  if [ $debug -eq 1 ]; then
    echo " "
    echo USE_MAKE_TO_TEST = $USE_MAKE_TO_TEST
    echo TEST_EXEC = $TEST_EXEC
    echo TEST_EXEC_OPT = $TEST_EXEC_OPT
    echo TEST_DIR = $TEST_DIR
    echo CVS_DIRS = $CVS_DIRS
    echo MAKE = $MAKE
    echo BUILD_COMMANDS = $BUILD_COMMANDS
    echo MAIL_COMPLETE = $MAIL_COMPLETE
    echo MAIL_SUMMARY = $MAIL_SUMMARY
    echo MAIL_FAILURE = $MAIL_FAILURE
    echo MAIL_SUBJECT = $MAIL_SUBJECT
    echo MAIL_COMMAND = $MAIL_COMMAND
    echo RESULTS_FILE = $RESULTS_FILE
    echo RESULTS_FILE2 = $RESULTS_FILE2
    echo REPEAT_COMMAND = $REPEAT_COMMAND
    echo TEST_KEYS = $TEST_KEYS
    echo TEMP = $TEMP
    echo POST_TEST_COMMANDS = $POST_TEST_COMMANDS
    echo OUTPUT_TIME = $OUTPUT_TIME
  fi

  if [ -n "$RESULTS_FILE" ]; then
    touch $RESULTS_FILE
    if [ ! -w $RESULTS_FILE ]; then
      echo "ERROR - Unable to write to results file: $RESULTS_FILE"
      exit 1
    fi
  else
    echo "ERROR - Aborting.  No results file specified"
    exit 1
  fi

  util_dir=$TEST_DIR/util
  if [ ! -d $TEST_DIR -o ! -r $TEST_DIR ]; then
    echo "Test directory $TEST_DIR does not exist"
    echo "or you cannot read and use the files in it"
    exit 1
  elif [ ! -d $TEMP -o ! -w $TEMP -o ! -r $TEMP ]; then
    echo "Temp directory $TEMP is not readable,"
    echo "writeable, or does not exist"
    echo "Check your \$TEMP variable and try again"
    exit 1
  else
    if [ ! -n "`echo $TEST_EXEC | grep '^/'`" ]; then
      TEST_EXEC=${pwd_dir}/$TEST_EXEC
    fi
  fi
}

function do_cvs_updates {
  # Do a cvs update in each directory in CVS_DIRS
  cvs_results_file=$TEMP/cvs.$$
  cvs_errors=0
  num_cvs_dirs=0
  if [ -n '$CVS_DIRS' ]; then
    # Write the header for the CVS output
    write_section_begin "CVS Update Results" $cvs_results_file
    write_section_end $cvs_results_file
    for dir in $CVS_DIRS
    do
      num_cvs_dirs=`expr $num_cvs_dirs + 1`
      # Update the directory if it exists
      print -n "Running CVS Update in $dir..."
      echo "---------------------------------------" >> $cvs_results_file
      echo "  ----- cvs update -d -P in $dir ---" >> $cvs_results_file
      if [ -d $dir ]; then
        cd $dir
        if [ -f cvs-update.out ]; then
          $RM -f cvs-update.out
        fi
        cvs update -P -d > cvs-update.out 2>&1
        # Get the number of updates, merges, and conflicts
        cur_num_merges=`grep "^M " cvs-update.out | wc -l | awk '{print $1}'`
	# We can't use this next line because the Sun's grep can't handle it.
        #cur_num_updates=`grep -e "^U " -e "^A " -e "^P " cvs-update.out | wc -l | awk '{print $1}'`
	# instead, use cur_num_conflicts as a temp variable and run it 3 times,
	# once for each type of update
	cur_num_updates=`grep "^U " cvs-update.out | wc -l | awk '{print $1}'`
	cur_num_conflicts=`grep "^A " cvs-update.out | wc -l | awk '{print $1}'`
	cur_num_updates=`expr $cur_num_updates + $cur_num_conflicts`
	cur_num_conflicts=`grep "^P " cvs-update.out | wc -l | awk '{print $1}'`
	cur_num_updates=`expr $cur_num_updates + $cur_num_conflicts`
	# Now actually count the number of conflicts
        cur_num_conflicts=`grep "^C " cvs-update.out | wc -l | awk '{print $1}'`
        if [ $cur_num_conflicts != 0 ]; then
          echo "\n   ERROR - $cur_num_conflicts conflicts occurred in $dir"
          echo "\n   ERROR - $cur_num_conflicts conflicts" >> $cvs_results_file
          cvs_errors=`expr $cvs_errors + 1`
        fi
        echo "   $cur_num_merges merges" >> $cvs_results_file
        echo "   $cur_num_updates updates\n" >> $cvs_results_file
	echo "   CVS Output:" >> $cvs_results_file
	cat cvs-update.out >> $cvs_results_file
	$RM -f cvs-update.out
	cd $pwd_dir
      else
        echo "\nERROR: $dir not found"
        echo "   ERROR - $dir not found" >> $cvs_results_file
        cvs_errors=`expr $cvs_errors + 1`
      fi
      echo "\n---------------------------------------\n" >> $cvs_results_file
      echo "done"
    done
  fi
}

function do_build_commands {
  if [ ! -n "$BUILD_COMMANDS" ]; then
    return 0
  fi
  
  # Just execute the commands and make sure
  # the return value is 0
  build_results_file=$TEMP/build.$$
  echo "executing '${BUILD_COMMANDS}'"
  touch $build_results_file
  write_section_begin "Build Commands" $build_results_file
  echo "* ${BUILD_COMMANDS}" >> $build_results_file
  echo "*\n* Output:" >> $build_results_file
  (eval ${BUILD_COMMANDS}) >> $build_results_file 2>&1
  build_errors=$?
  write_section_end $build_results_file
  cd $pwd_dir
}

function do_tests {
  test_results_file=$TEMP/test.$$
  write_section_begin "Test Results" $test_results_file
  write_section_end $test_results_file
  echo "Running tests..."
  
  coreDumps=0

  for TEST_EXEC in driverc++/mergechk facetdriver/facets facetdriver/facets2 exoIIfacet/exo gomadrive/drive
  do
  cd $TEST_DIR
  num_core=0
  
  if [ $TEST_EXEC = 'driverc++/mergechk' ]; then
    TEST_OPTIONS='driverc++/merge.sat'
  elif [ $TEST_EXEC = 'facetdriver/facets' ]; then
    TEST_OPTIONS='30.0'
  elif [ $TEST_EXEC = 'facetdriver/facets2' ]; then
    TEST_OPTIONS='135.0'
  elif [ $TEST_EXEC = 'exoIIfacet/exo' ]; then
    TEST_OPTIONS='exoIIfacet/exo.g -sideset 1 2 3 4 5 6'
  elif [ $TEST_EXEC = 'gomadrive/drive' ]; then
    TEST_OPTIONS='gomadrive/input.txt'
  fi
  $TEST_EXEC $TEST_OPTIONS > temp_out.$$ 2>&1
  CUBITStatus=$?
   
  # Clean up files we don't want around

    # Count the number of errors and interrupts
    num_err=`grep "^ERROR" temp_out.$$ | wc -l | awk '{print $1}'`
    num_intr=`sed -n "s/Interrupt Detected. CUBIT Exiting.//p" temp_out.$$ | wc -l | awk '{print $1}'`
    if [ `find . -name core` ]; then
      num_core=1
      echo "num_core = $num_core"
      ((total_cores = $total_cores + 1))
      find . -name core -exec rm -f \{\} \;
    fi
    num_bad_commands=`grep -c "Command Not Found" temp_out.$$`
    
    # Now output a header for this file
    echo "=================================================================" >> $test_results_file
    echo "      TEST SUMMARY for $TEST_EXEC\n" >> $test_results_file
    if [ $num_core -ne 0 ]; then
      echo "      $num_core core dump(s) occurred" >> $test_results_file
          echo "ERROR: ${TEST_EXEC} core dumped"
            tests_with_errors=`echo $tests_with_errors $TEST_EXEC`
    elif [ $num_intr != 0 ]; then
      echo "      INTERRUPT DETECTED" >> $test_results_file
            echo "ERROR: ${TEST_EXEC} interrupted"
       tests_with_errors=`echo $tests_with_errors $TEST_EXEC`
    elif [ $CUBITStatus != 0 ]; then
        echo " *** ERROR: ${TEST_EXEC} completed with errors ***"
	echo "CUBITStatus = ${CUBITStatus}"
      tests_with_errors=`echo $tests_with_errors $TEST_EXEC`
    else
        echo "Completed $TEST_EXEC test"
    fi
    if [ $num_err != 0 ]; then
      echo "      $num_err ERRORS Found" >> $test_results_file
    fi
    if [ $num_bad_commands -ne 0 ]; then
      echo "      $num_bad_commands Command Not Found(s) occurred" >> $test_results_file
    fi
    echo "      Test completed with return value $CUBITStatus" >> $test_results_file
    echo "" >> $test_results_file
    echo "   ===========================================================" >> $test_results_file
    rm -f temp_out.$$
    cd ..
  done
  if [ -n "$tests_with_errors" ]; then
    echo "----------" `echo $tests_with_errors | wc -w | awk '{print $1}'` \
         "TEST(S) contained ERRORS --------------"
  fi
  
  cd $pwd_dir
}

function do_post_test_commands {
  if [ ! -n "$POST_TEST_COMMANDS" ]; then
    return 0
  fi
  
  # We'll just continue to use test.$$
  post_test_results_file=$TEMP/test.$$
  # Just execute the commands and make sure
  # the return value is 0
  echo "executing '${POST_TEST_COMMANDS}'"
  write_section_begin "Post-Test Commands" $post_test_results_file
  echo "* ${POST_TEST_COMMANDS}" >> $post_test_results_file
  echo "*\n* Output:" >> $post_test_results_file
  (eval ${POST_TEST_COMMANDS}) >> $post_test_results_file 2>&1
  post_test_errors=$?
  write_section_end $post_test_results_file
  cd $pwd_dir
}

####################################################################
#  This is the actual script (finally!!!)
if [[ -r cgm_test.kshrc ]]
then
	. ./cgm_test.kshrc
fi


initialize_variables "$@"
check_variables "$@"
trap 'echo "*** Aborting tests.  Results file may be incomplete or from a previous test. ***"; $RM -f $TEMP/*.$$; exit 1' 1 2 15
do_cvs_updates
if [ $cvs_errors -eq 0 ]; then
  do_build_commands
  if [ $build_errors -eq 0 ]; then
    do_tests
    if [ ! -n "$tests_with_errors" ]; then
      do_post_test_commands
    fi
  fi
fi
write_results_file
cp "$RESULTS_FILE" "$RESULTS_FILE2"
if [ -n "$REPEAT_COMMAND" ]; then
  echo "Running repeat_command:" $REPEAT_COMMAND
  $REPEAT_COMMAND
fi
